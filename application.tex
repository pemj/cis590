\section{Self-Driving Cars: an Application of our Framework}
\label{sec:-application}

\subsection{Background}
Long a fascination for inventors, the seed for autonomous cars was sewn 
in the 1960s with the Stanford Cart\cite{moravec1990stanford}. The cart 
navigated small spaces by taking photos of its surroundings and using a 
simple computer program to analyze the photos and choose a path of 
travel. Two decades later, a vision-guided Mercedes-Benz van designed 
by Ernst Dickmanns navigated empty streets at speeds of up to 39mph. By 
2009, Google began privately testing anonymous vehicles on closed 
streets, and by 2012, changes in various states' laws allowed for 
testing on city streets. As of 2016, Google claims over 1.3 million 
autonomous miles driven, although Google's cars are limited 
to 25mph and must always have a human driver present.\cite{wired}  As 
driverless car technology improves and becomes more widely implemented, 
the true societal impact of this technology will begin to be felt.

\subsection{Application}

We're in an interesting time regarding autonomous vehicle technology. 
It's clear that the technology will become widely used, but it has yet 
to actually happen. This presents an opportunity to consider how, as a 
society, we should approach the ethical ramifications of this
potentially society-altering technology. To do so, we'll apply the 
ethical framework laid forth earlier in this paper to autonomous cars.

To begin, it is important to identify the three main stakeholders in 
driverless car technology: the public, the government, and corporations. 
These stakeholders are universal, but the beliefs of each stakeholder can
vary depending on cultural biases, value systems, and economic status. Also,
the weight given to each stakeholder can vary based on these factors. In the 
interest of concision, this application will focus on a generalized idea of American 
cultural bias, values, and economic status.

Because the United States is such a demographically, economically, and 
culturally diverse country, it is difficult to make generalizations of 
the country as a whole. That being said, it is possible to extrapolate 
mainstream value systems of our three stakeholders (public, government, and 
corporations). The American public values individualism and personal rights. 
Corporations value free market principles and the acquisition of capital. 
The government acts as a mediator (sometimes poorly) between the interests of
corporations and of individuals. Each stakeholder has the power to act on the other 
and bring about change. With the stakeholders, value systems, and power structure
identified, it is possible to apply our ethical framework to autonomous vehicle 
technology in the United States.

Autonomous vehicles have a lot to offer a utilitarian. A recent 
Virginia Tech study\cite{blanco2016automated} shows that the crash 
rate of Google's self-driving cars is lower than the national crash rate 
of conventional cars. Google's cars experience 3.2 crashes per million 
miles while conventional cars experience 4.2 crashes per million miles. 
With autonomous vehicle technology continually improving, the technology 
will become even safer in the years to come. This sounds great, but is a full on, 
no-strings-attached embrace of the technology the best course of action? For a 
utilitarian, the answer may be "yes", but there is a problem with this approach. 
Autonomous vehicles will face a variety of moral dilemmas, and a one-size-fits all 
ethical framework doesn't cover all of these possibilities sufficiently. 

Consider the following example: during the November 2015 terror attacks 
in Paris, ride-sharing app Uber's algorithmic design dramatically raised 
prices in the areas near the attacks due to an increase in ride requests 
from people trying to flee the chaos. In this situation, stakeholders (public and 
corporate) were in direct opposition to each other. Uber saw the 
situation as a moneymaking opportunity, while the public saw Uber as 
price gouging and profiting from a disaster. Eventually, Uber gave in 
to public demand and lowered prices. Situations such as this will become 
the norm in the age of autonomous cars. In fact, Uber is aggressively 
seeking driverless car technology for use in their taxi company.

In the case of Uber raising the prices on people fleeing a disaster, utilitarianism 
supports profit maximization as a means of supporting the greatest societal good.
Clearly, this is a morally unfavorable position for the public, but fortunately, the moral 
framework set forth in this paper allows an exception to utilitarianism
on the basis of protecting an individual's welfare and well-being. In the case
of the Paris attacks or hypothetical future situations involving Uber autonomous
vehicles, our moral framework prioritizes lives in danger over profits in dangers. 

Consider another hypothetical example: you're riding down the highway in your 
autonomous car and a large object falls off of a truck in front of you. 
Your car cannot stop itself in time and must decide on the best course 
of action. If it continues straight and runs into the object, it places 
your life in serious jeopardy. There are two motorcyclists on either 
side of your car; one is wearing a helmet and the other is not. Swerving 
into one of the motorcyclists will likely save your life, but jeopardize 
the life of one of the motorcyclists.

With strict utilitarianism, your car would likely swerve into the 
motorcyclist wearing the helmet because it creates the best chance of 
survival for all involved, but is it fair to punish a motorcyclist for being 
responsible and wearing a helmet? What are the legal and moral ramifications 
of such a programmed decision? In this scenario, our ethical 
framework would fall back onto the autonomy of the individual.
They could decide how their car is programmed to react in cases such as these.
Alternatively, self-driving cars could rely on an element on randomness
in making such decisions or even cede control to a human driver (local
or remote) despite the car's ability to handle situations such as this without
human intervention. The important point is leaving autonomy in the hands of
the individual, not the machine. 

While far from foolproof, our ethical framework allows for important 
exceptions to utilitarianism. The implementation of 
driverless cars will undoubtedly lead to many unique moral dilemmas, 
therefore the existence of \textit{fallback rules} to a society's moral framework
will be critical. In the previous examples, the \textit{fallback rules} of our ethical framework placed 
health and well-being above financial profit and the autonomy of 
a human over the autonomy of a machine. These are only two examples of 
the multitudes of moral dilemmas that will become ever-present in a driverless
car future, and it is critical that we continue to work toward developing an
ethical framework to deal with every possibility. 

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
